hydra:
  run:
    dir: ckpts/${model.name}_${model.mel_spec.mel_spec_type}_${model.tokenizer}_${datasets.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

datasets:
  name: Emilia_ZH_EN  # dataset name
  batch_size_per_gpu: 19200  # reduced batch due to extra embedding processing
  batch_size_type: frame
  max_samples: 32  # reduced for memory with embeddings
  num_workers: 8
  embedding_cache_dir: null  # path to precomputed embeddings, null for online extraction

optim:
  epochs: 5  # fewer epochs needed since base model is frozen
  learning_rate: 3e-4  # higher LR for conditioning modules (small param count)
  num_warmup_updates: 2000  # faster warmup since fewer params
  grad_accumulation_steps: 1
  max_grad_norm: 1.0
  bnb_optimizer: False

model:
  name: F5TTS_Enhanced  # model name
  tokenizer: char
  tokenizer_path: null
  backbone: EnhancedDiT

  # Base architecture (same as F5TTS_Base to load pretrained weights)
  arch:
    dim: 1024
    depth: 22
    heads: 16
    ff_mult: 2
    text_dim: 512
    text_mask_padding: False
    conv_layers: 4
    pe_attn_head: 1
    attn_backend: torch
    attn_mask_enabled: False
    checkpoint_activations: False

  # NEW: Conditioning architecture
  conditioning:
    speaker_emb_dim: 512   # speaker embedding dimension
    emotion_emb_dim: 512   # emotion embedding dimension

    # Speaker encoder (frozen pretrained model)
    speaker_encoder:
      backend: wavlm_sv    # "wavlm_sv" | "ecapa_tdnn" | "resemblyzer"

    # Emotion encoder (frozen pretrained model)
    emotion_encoder:
      backend: emotion2vec_base  # "emotion2vec_base" | "wav2vec2_ser" | "hubert_ser"
      frame_level: true          # enable time-varying emotion control

    # Injection strategies
    use_adaln_cond: true         # AdaLN modulation from global embeddings
    use_input_add_cond: true     # embedding addition at input level
    use_cross_attn_cond: true    # cross-attention for frame-level emotion

    # Cross-attention configuration
    cross_attn_layers: [0, 4, 8, 12, 16, 20]  # every 4th block
    cross_attn_heads: 8
    cross_attn_dim_head: 64

    # Training dropout for multi-condition CFG
    speaker_drop_prob: 0.1
    emotion_drop_prob: 0.1

  mel_spec:
    target_sample_rate: 24000
    n_mel_channels: 100
    hop_length: 256
    win_length: 1024
    n_fft: 1024
    mel_spec_type: vocos

  vocoder:
    is_local: False
    local_path: null

# Finetuning strategy
finetune:
  freeze_base: true           # freeze original F5-TTS weights
  unfreeze_top_k_blocks: 0    # optionally unfreeze top-K DiT blocks (0 = fully frozen)
  pretrain_ckpt: null          # path to original F5-TTS checkpoint

# Inference defaults
inference:
  nfe_step: 32
  cfg_strength: 2.0
  emotion_cfg_strength: 1.0   # emotion guidance strength (0 = no emotion, 2+ = strong)
  sway_sampling_coef: -1.0
  speed: 1.0

ckpts:
  logger: wandb
  wandb_project: F5TTS-Enhanced
  wandb_run_name: ${model.name}_${model.mel_spec.mel_spec_type}_${model.tokenizer}_${datasets.name}
  wandb_resume_id: null
  log_samples: True
  save_per_updates: 5000
  keep_last_n_checkpoints: 5
  last_per_updates: 1000
  save_dir: ckpts/${model.name}_${model.mel_spec.mel_spec_type}_${model.tokenizer}_${datasets.name}
