# ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ F5-TTS Enhanced

## Ð¢Ñ€Ð¸ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ñ â€” Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ²Ð¾Ð¹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                â”‚
â”‚  ðŸŽ¤ Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ 1: ÐšÐ»Ð¾Ð½ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ°                             â”‚
â”‚     Ð”Ð°Ð½Ð½Ñ‹Ðµ:  5-30 Ð¼Ð¸Ð½ÑƒÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°                  â”‚
â”‚     Ð’Ñ€ÐµÐ¼Ñ:   1-3 Ñ‡Ð°ÑÐ° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ                                 â”‚
â”‚     Ð˜Ñ‚Ð¾Ð³:    TTS Ñ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°                â”‚
â”‚                                                                â”‚
â”‚  ðŸŽ­ Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ 2: Ð“Ð¾Ð»Ð¾Ñ + ÑÐ¼Ð¾Ñ†Ð¸Ð¸                                 â”‚
â”‚     Ð”Ð°Ð½Ð½Ñ‹Ðµ:  1-5 Ñ‡Ð°ÑÐ¾Ð² ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ€ÐµÑ‡Ð¸                     â”‚
â”‚     Ð’Ñ€ÐµÐ¼Ñ:   3-10 Ñ‡Ð°ÑÐ¾Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ                               â”‚
â”‚     Ð˜Ñ‚Ð¾Ð³:    TTS Ñ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ¾Ð¼ Ð³Ð¾Ð»Ð¾ÑÐ° Ð˜ ÑÐ¼Ð¾Ñ†Ð¸Ð¸ Ð¸Ð· Ñ€ÐµÑ„ÐµÑ€ÐµÐ½ÑÐ°     â”‚
â”‚                                                                â”‚
â”‚  ðŸŒ Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ 3: Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð°Ñ multi-speaker Ð¼Ð¾Ð´ÐµÐ»ÑŒ             â”‚
â”‚     Ð”Ð°Ð½Ð½Ñ‹Ðµ:  10-100+ Ñ‡Ð°ÑÐ¾Ð², 50+ ÑÐ¿Ð¸ÐºÐµÑ€Ð¾Ð², Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ·Ñ‹ÐºÐ¾Ð²     â”‚
â”‚     Ð’Ñ€ÐµÐ¼Ñ:   10-50 Ñ‡Ð°ÑÐ¾Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ                              â”‚
â”‚     Ð˜Ñ‚Ð¾Ð³:    ÐšÐ»Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð»ÑŽÐ±Ð¾Ð³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ° + ÑÐ¼Ð¾Ñ†Ð¸Ð¸ + ÑÐ·Ñ‹ÐºÐ¸      â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ 1: ÐšÐ»Ð¾Ð½ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ°

### Ð§Ñ‚Ð¾ Ð½ÑƒÐ¶Ð½Ð¾

ÐŸÐ°Ð¿ÐºÐ° Ñ Ð°ÑƒÐ´Ð¸Ð¾Ð·Ð°Ð¿Ð¸ÑÑÐ¼Ð¸ Ñ†ÐµÐ»ÐµÐ²Ð¾Ð³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ°. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð½Ðµ Ð²Ð°Ð¶ÐµÐ½ (WAV, FLAC, MP3).
Ð–ÐµÐ»Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾: Ñ‡Ð¸ÑÑ‚Ð°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð±ÐµÐ· Ñ„Ð¾Ð½Ð¾Ð²Ð¾Ð³Ð¾ ÑˆÑƒÐ¼Ð°, Ñ„Ð°Ð¹Ð»Ñ‹ Ð¿Ð¾ 3-15 ÑÐµÐºÑƒÐ½Ð´.

```
my_voice/
â”œâ”€â”€ recording_001.wav     # "ÐŸÑ€Ð¸Ð²ÐµÑ‚, Ð¼ÐµÐ½Ñ Ð·Ð¾Ð²ÑƒÑ‚ ÐÐ»ÐµÐºÑÐµÐ¹"
â”œâ”€â”€ recording_001.txt     # Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
â”œâ”€â”€ recording_002.wav
â”œâ”€â”€ recording_002.txt
â”œâ”€â”€ ...
â””â”€â”€ recording_050.wav
```

### ÐžÐ´Ð½Ð° ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°

```bash
python custom_train.py single_speaker \
    --audio_dir ./my_voice \
    --output_dir ./my_model
```

Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸:
1. ÐÐ°Ð¹Ð´Ñ‘Ñ‚ Ð²ÑÐµ Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»Ñ‹
2. ÐžÑ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÑ‚ Ð±Ð¸Ñ‚Ñ‹Ðµ Ð¸ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ/Ð´Ð»Ð¸Ð½Ð½Ñ‹Ðµ
3. Ð¡Ð¾Ð±ÐµÑ€Ñ‘Ñ‚ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ `.txt` Ñ€ÑÐ´Ð¾Ð¼ Ñ `.wav`)
4. Ð˜Ð·Ð²Ð»ÐµÑ‡Ñ‘Ñ‚ speaker + emotion ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸
5. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸
6. Ð’Ñ‹Ð±ÐµÑ€ÐµÑ‚ Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ-Ñ„Ð°Ð¹Ð»

### Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚

```
my_model/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ pretrained_model_1200000.pt    # Ð±Ð°Ð·Ð° F5-TTS
â”‚   â””â”€â”€ model_last.pt                  # Ð²Ð°ÑˆÐ° Ð¼Ð¾Ð´ÐµÐ»ÑŒ
â”œâ”€â”€ best_reference.wav                  # Ð»ÑƒÑ‡ÑˆÐ¸Ð¹ Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ
â”œâ”€â”€ dataset/                            # Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
â””â”€â”€ embeddings/                         # ÐºÑÑˆ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²
```

### Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ

```bash
python custom_train.py test \
    --checkpoint ./my_model/checkpoints/model_last.pt \
    --ref_audio ./my_model/best_reference.wav \
    --text "ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¹ ÐºÐ»Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð³Ð¾Ð»Ð¾Ñ. Ð—Ð²ÑƒÑ‡Ð¸Ñ‚ Ð½ÐµÐ¿Ð»Ð¾Ñ…Ð¾, Ð¿Ñ€Ð°Ð²Ð´Ð°?"
# â†’ test_output.wav
```

### ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ°

```bash
# Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ„Ð°Ð¹Ð» Ñ Ñ‚ÐµÐºÑÑ‚Ð°Ð¼Ð¸
cat > texts.txt << EOF
ÐŸÐµÑ€Ð²Ð°Ñ Ð³Ð»Ð°Ð²Ð°. Ð–Ð¸Ð»-Ð±Ñ‹Ð» Ð¾Ð´Ð¸Ð½ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚.
ÐžÐ½ Ð¾Ñ‡ÐµÐ½ÑŒ Ð»ÑŽÐ±Ð¸Ð» Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸.
ÐžÐ´Ð½Ð°Ð¶Ð´Ñ‹ Ð¾Ð½ Ð¾Ð±ÑƒÑ‡Ð¸Ð» Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ð»Ð° ÐµÐ³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼.
EOF

python custom_train.py batch \
    --checkpoint ./my_model/checkpoints/model_last.pt \
    --ref_audio ./my_model/best_reference.wav \
    --input_texts texts.txt \
    --output_dir ./audiobook
# â†’ audiobook/0001.wav, 0002.wav, 0003.wav
```

### Ð¡Ð¾Ð²ÐµÑ‚Ñ‹ Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ°

| ÐžÐ±ÑŠÑ‘Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ñ… | ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ð¾Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ | Ð­Ð¿Ð¾Ñ… | Ð’Ñ€ÐµÐ¼Ñ (RTX 3090) |
|-------------|-------------------|------|-------------------|
| 5 Ð¼Ð¸Ð½ÑƒÑ‚ | Ð£Ð·Ð½Ð°Ð²Ð°ÐµÐ¼Ñ‹Ð¹ Ñ‚ÐµÐ¼Ð±Ñ€, Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹ Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ | 50 | ~1 Ñ‡Ð°Ñ |
| 15 Ð¼Ð¸Ð½ÑƒÑ‚ | Ð¥Ð¾Ñ€Ð¾ÑˆÐµÐµ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð¾ | 20 | ~2 Ñ‡Ð°ÑÐ° |
| 30 Ð¼Ð¸Ð½ÑƒÑ‚ | Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ | 10 | ~2 Ñ‡Ð°ÑÐ° |
| 1+ Ñ‡Ð°Ñ | ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ | 5 | ~2 Ñ‡Ð°ÑÐ° |

**ÐšÐ°Ðº ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¸ Ð¼Ð°Ð»Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ…:**
- Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°Ð¹Ñ‚Ðµ Ð² Ñ‚Ð¸Ñ…Ð¾Ð¼ Ð¿Ð¾Ð¼ÐµÑ‰ÐµÐ½Ð¸Ð¸
- Ð“Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚Ðµ Ñ‡Ñ‘Ñ‚ÐºÐ¾ Ð¸ Ð² Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ð¼ Ñ‚ÐµÐ¼Ð¿Ðµ
- Ð Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹ Ð»ÑƒÑ‡ÑˆÐµ, Ñ‡ÐµÐ¼ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÐµÐ½Ð¸Ðµ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°
- Ð¤Ð°Ð¹Ð»Ñ‹ Ð¿Ð¾ 5-10 ÑÐµÐºÑƒÐ½Ð´ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹
- Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ `.txt` Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸ â€” ÑÑ‚Ð¾ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚

---

## Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ 2: Ð“Ð¾Ð»Ð¾Ñ + ÑÐ¼Ð¾Ñ†Ð¸Ð¸

### Ð§Ñ‚Ð¾ Ð½ÑƒÐ¶Ð½Ð¾

ÐÑƒÐ´Ð¸Ð¾ Ñ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ‹Ð¼Ð¸ ÑÐ¼Ð¾Ñ†Ð¸ÑÐ¼Ð¸. Ð˜Ð´ÐµÐ°Ð»ÑŒÐ½Ð¾: Ð°ÐºÑ‚Ñ‘Ñ€ÑÐºÐ°Ñ Ð¾Ð·Ð²ÑƒÑ‡ÐºÐ° Ð¸Ð»Ð¸
ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¸. ÐÑƒÐ¶ÐµÐ½ Ñ„Ð°Ð¹Ð» Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ….

```
emotional_data/
â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ happy_001.wav
â”‚   â””â”€â”€ ...
â”œâ”€â”€ sad/
â”‚   â”œâ”€â”€ sad_001.wav
â”‚   â””â”€â”€ ...
â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ angry_001.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ metadata.csv
```

**metadata.csv:**
```
emotional_data/happy/happy_001.wav|ÐšÐ°ÐºÐ¾Ð¹ Ð·Ð°Ð¼ÐµÑ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÑÐµÐ³Ð¾Ð´Ð½Ñ Ð´ÐµÐ½ÑŒ!|ru
emotional_data/sad/sad_001.wav|ÐœÐ½Ðµ Ñ‚Ð°Ðº Ð¾Ð´Ð¸Ð½Ð¾ÐºÐ¾ ÑÐµÐ³Ð¾Ð´Ð½Ñ.|ru
emotional_data/angry/angry_001.wav|Ð­Ñ‚Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½ÐµÐ²Ñ‹Ð½Ð¾ÑÐ¸Ð¼Ð¾!|ru
```

### Ð—Ð°Ð¿ÑƒÑÐº

```bash
python custom_train.py emotional \
    --audio_dir ./emotional_data \
    --metadata ./emotional_data/metadata.csv \
    --output_dir ./emo_model
```

### ÐšÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐ¼Ð¾Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐµ

ÐšÐ»ÑŽÑ‡ÐµÐ²Ð°Ñ Ð¸Ð´ÐµÑ: **ÑÐ¼Ð¾Ñ†Ð¸Ñ Ð±ÐµÑ€Ñ‘Ñ‚ÑÑ Ð¸Ð· Ñ€ÐµÑ„ÐµÑ€ÐµÐ½ÑÐ½Ð¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ð¾**.
ÐŸÐ¾Ð´Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ Ñ Ð½ÑƒÐ¶Ð½Ð¾Ð¹ ÑÐ¼Ð¾Ñ†Ð¸ÐµÐ¹:

```bash
# Ð Ð°Ð´Ð¾ÑÑ‚Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
python custom_train.py test \
    --checkpoint ./emo_model/checkpoints/model_last.pt \
    --ref_audio ./emotional_data/happy/happy_001.wav \
    --text "Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð±ÑƒÐ´ÐµÑ‚ ÐµÑ‰Ñ‘ Ð»ÑƒÑ‡ÑˆÐµ!" \
    --emotion_strength 1.5

# Ð“Ñ€ÑƒÑÑ‚Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
python custom_train.py test \
    --checkpoint ./emo_model/checkpoints/model_last.pt \
    --ref_audio ./emotional_data/sad/sad_001.wav \
    --text "Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð±ÑƒÐ´ÐµÑ‚ ÐµÑ‰Ñ‘ Ð»ÑƒÑ‡ÑˆÐµ." \
    --emotion_strength 1.5

# Ð¢Ð¾Ñ‚ Ð¶Ðµ Ñ‚ÐµÐºÑÑ‚, Ð½Ð¾ ÑÐ¼Ð¾Ñ†Ð¸Ñ Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ Ñ‡ÐµÑ€ÐµÐ· Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ!
```

### emotion_strength â€” ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¸Ð½Ñ‚ÐµÐ½ÑÐ¸Ð²Ð½Ð¾ÑÑ‚ÑŒÑŽ

```
0.0  â†’ ÐŸÐ¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð°Ñ Ñ€ÐµÑ‡ÑŒ (ÑÐ¼Ð¾Ñ†Ð¸Ñ Ð¸Ð· Ñ€ÐµÑ„ÐµÑ€ÐµÐ½ÑÐ° Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ)
0.5  â†’ Ð›Ñ‘Ð³ÐºÐ¸Ð¹ Ð½Ð°Ð¼Ñ‘Ðº Ð½Ð° ÑÐ¼Ð¾Ñ†Ð¸ÑŽ
1.0  â†’ Ð­Ð¼Ð¾Ñ†Ð¸Ñ ÐºÐ°Ðº Ð² Ñ€ÐµÑ„ÐµÑ€ÐµÐ½ÑÐµ (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ)
1.5  â†’ Ð£ÑÐ¸Ð»ÐµÐ½Ð½Ð°Ñ ÑÐ¼Ð¾Ñ†Ð¸Ñ (Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ ÑÑ€ÐºÐ¸Ñ… ÑÑ„Ñ„ÐµÐºÑ‚Ð¾Ð²)
2.0  â†’ Ð¡Ð¸Ð»ÑŒÐ½Ð¾ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð½Ð°Ñ ÑÐ¼Ð¾Ñ†Ð¸Ñ
3.0+ â†’ ÐœÐ¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð½ÐµÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ (Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹)
```

### ÐšÑ€Ð¾ÑÑ-Ð»Ð¸Ð½Ð³Ð²Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿ÐµÑ€ÐµÐ½Ð¾Ñ ÑÐ¼Ð¾Ñ†Ð¸Ð¹

Ð­Ð¼Ð¾Ñ†Ð¸Ñ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ÑÑ Ð¸Ð· Ð°ÐºÑƒÑÑ‚Ð¸ÐºÐ¸, Ð½Ðµ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°.
Ð ÐµÑ„ÐµÑ€ÐµÐ½Ñ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð½Ð° Ð›Ð®Ð‘ÐžÐœ ÑÐ·Ñ‹ÐºÐµ:

```bash
# ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ â†’ Ñ€ÑƒÑÑÐºÐ°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
python custom_train.py test \
    --checkpoint ./emo_model/checkpoints/model_last.pt \
    --ref_audio ./english_happy_speaker.wav \
    --text "Ð¯ Ñ‚Ð°Ðº Ñ€Ð°Ð´, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚!" \
    --emotion_strength 1.0
```

---

## Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ 3: Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ

### Ð§Ñ‚Ð¾ Ð½ÑƒÐ¶Ð½Ð¾

Ð‘Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð½Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚. Ð”Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð½ÑƒÐ¶Ð½Ð¾
Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ‚ÑŒ Ð·Ð°Ñ€Ð°Ð½ÐµÐµ Ñ‡ÐµÑ€ÐµÐ· `prepare_data.py`:

```bash
# Ð¨Ð°Ð³ 1: Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ‚ÑŒ dataset
python -m f5_tts.scripts.prepare_data --stage prepare \
    --audio_dir /data/audio \
    --metadata /data/metadata.csv \
    --output_dir /data/dataset

# Ð¨Ð°Ð³ 2: Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ (Ð´Ð¾Ð»Ð³Ð¾, Ð½Ð¾ Ð¾Ð´Ð½Ð¾ÐºÑ€Ð°Ñ‚Ð½Ð¾)
python -m f5_tts.scripts.prepare_data --stage embeddings \
    --dataset_dir /data/dataset \
    --embedding_dir /data/embeddings \
    --device cuda

# Ð¨Ð°Ð³ 3: Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚ÑŒ
python custom_train.py multi_speaker \
    --dataset_dir /data/dataset \
    --embedding_dir /data/embeddings \
    --output_dir ./universal_model
```

### Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ð¼

```
ÐœÐ¸Ð½Ð¸Ð¼ÑƒÐ¼ Ð´Ð»Ñ Ð¿Ñ€Ð¸ÐµÐ¼Ð»ÐµÐ¼Ð¾Ð³Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°:
  - 10 Ñ‡Ð°ÑÐ¾Ð² Ð°ÑƒÐ´Ð¸Ð¾
  - 50 ÑÐ¿Ð¸ÐºÐµÑ€Ð¾Ð²
  - 2+ ÑÐ·Ñ‹ÐºÐ°
  - Ð¥Ð¾Ñ‚Ñ Ð±Ñ‹ 1 Ñ‡Ð°Ñ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ€ÐµÑ‡Ð¸

Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€:
  - 50-100 Ñ‡Ð°ÑÐ¾Ð² Ð°ÑƒÐ´Ð¸Ð¾
  - 200+ ÑÐ¿Ð¸ÐºÐµÑ€Ð¾Ð²
  - 4-6 ÑÐ·Ñ‹ÐºÐ¾Ð² (Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾: RU, EN)
  - 5-10 Ñ‡Ð°ÑÐ¾Ð² ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ€ÐµÑ‡Ð¸

Ð”Ð»Ñ production:
  - 500+ Ñ‡Ð°ÑÐ¾Ð²
  - 1000+ ÑÐ¿Ð¸ÐºÐµÑ€Ð¾Ð²
  - 10+ ÑÐ·Ñ‹ÐºÐ¾Ð²
  - Ð Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð½Ñ‹Ðµ ÑÑ‚Ð¸Ð»Ð¸: ÐºÐ½Ð¸Ð³Ð¸, Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¸, Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸, ÑÐ¼Ð¾Ñ†Ð¸Ð¸
```

### Ð”Ð²ÑƒÑ…ÑÑ‚Ð°Ð´Ð¸Ð¹Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ (Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ)

Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ 2 ÑÑ‚Ð°Ð´Ð¸Ð¸:

**Stage 1: Conditioning Ñ‚Ð¾Ð»ÑŒÐºÐ¾ (~20M params, 5.6%)**
```
Ð—Ð°Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ñ‹: Ð²ÑÐµ 335M Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² DiT
ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‚ÑÑ:  ConditioningAggregator, AdaLN, CrossAttn, InputAdd
LR:         3e-4 (Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¹, Ñ‚.Ðº. zero-init)
Ð­Ð¿Ð¾Ñ…:       3-10 (Ð·Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ Ð¾Ð±ÑŠÑ‘Ð¼Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…)
```

**Stage 2: + Top-4 DiT blocks (~45M params, 13%)**
```
Ð—Ð°Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ñ‹: Ð½Ð¸Ð¶Ð½Ð¸Ðµ 18 DiT blocks + base modules
ÐžÐ±ÑƒÑ‡Ð°ÑŽÑ‚ÑÑ:  conditioning + Ð²ÐµÑ€Ñ…Ð½Ð¸Ðµ 4 DiT blocks + output
LR:         1e-5 (Ð½Ð¸Ð·ÐºÐ¸Ð¹, Ñ‚.Ðº. pretrained)
Ð­Ð¿Ð¾Ñ…:       2
```

---

## Ð Ð°Ð±Ð¾Ñ‚Ð° Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð¼

### Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° checkpoint

```python
# Ð§Ñ‚Ð¾ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ model_last.pt:
{
    "ema_model_state_dict": {...},   # EMA Ð²ÐµÑÐ° (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð´Ð»Ñ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°)
    "optimizer_state_dict": {...},   # Ð´Ð»Ñ resume
    "scheduler_state_dict": {...},   # Ð´Ð»Ñ resume
    "update": 15000,                 # Ð½Ð¾Ð¼ÐµÑ€ ÑˆÐ°Ð³Ð°
    "epoch": 5,                      # Ð½Ð¾Ð¼ÐµÑ€ ÑÐ¿Ð¾Ñ…Ð¸
}
```

### Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð· Python

```python
from f5_tts.infer.enhanced_infer import (
    load_enhanced_model,
    load_vocoder,
    load_embedding_extractors,
    infer_enhanced,
)
import soundfile as sf

# Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð·)
model = load_enhanced_model("my_model/checkpoints/model_last.pt")
vocoder = load_vocoder()  # Vocos vocoder
spk_enc, emo_enc = load_embedding_extractors()

# Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
wave, sr = infer_enhanced(
    ref_audio="reference.wav",       # Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ (Ð»ÑŽÐ±Ð¾Ð¹ ÑÐ·Ñ‹Ðº)
    ref_text="",                      # Ð¼Ð¾Ð¶Ð½Ð¾ Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿ÑƒÑÑ‚Ñ‹Ð¼
    gen_text="Ð¢ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.",
    model=model,
    vocoder=vocoder,
    speaker_encoder=spk_enc,
    emotion_encoder=emo_enc,
    emotion_cfg_strength=1.0,         # 0=Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð¾, 1=ÐºÐ°Ðº Ð² ref, 2=ÑƒÑÐ¸Ð»ÐµÐ½Ð½Ð¾
    cfg_strength=2.0,                 # Ð¾Ð±Ñ‰Ð¸Ð¹ CFG (Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ 2.0)
    steps=32,                         # ÑˆÐ°Ð³Ð¸ ODE (Ð±Ð¾Ð»ÑŒÑˆÐµ=Ð»ÑƒÑ‡ÑˆÐµ, Ð¼ÐµÐ´Ð»ÐµÐ½Ð½ÐµÐµ)
    speed=1.0,                        # ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ñ€ÐµÑ‡Ð¸
)
sf.write("output.wav", wave, sr)
```

### ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°

| ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ | Ð”Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½ | ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ | Ð’Ð»Ð¸ÑÐ½Ð¸Ðµ |
|----------|---------|-------------|---------|
| `emotion_cfg_strength` | 0.0 â€” 3.0 | 1.0 | Ð˜Ð½Ñ‚ÐµÐ½ÑÐ¸Ð²Ð½Ð¾ÑÑ‚ÑŒ ÑÐ¼Ð¾Ñ†Ð¸Ð¸ |
| `cfg_strength` | 1.0 â€” 3.0 | 2.0 | ÐžÐ±Ñ‰ÐµÐµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾/Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¸Ðµ |
| `steps` | 8 â€” 64 | 32 | ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ (â†‘) vs ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ (â†“) |
| `speed` | 0.5 â€” 2.0 | 1.0 | Ð¡ÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ñ€ÐµÑ‡Ð¸ |
| `sway_sampling_coef` | -1.0 â€” 1.0 | -1.0 | Ð¡Ñ‚Ð¸Ð»ÑŒ ÑÐµÐ¼Ð¿Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ |

---

## ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ðµ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¸

### Ð”Ð¾Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð° Ð½Ð¾Ð²Ð¾Ð¼ Ð³Ð¾Ð»Ð¾ÑÐµ (Ð¿Ð¾Ð²ÐµÑ€Ñ… ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸)

```bash
# Ð’Ð·ÑÑ‚ÑŒ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÐºÐ°Ðº Ð±Ð°Ð·Ñƒ
python custom_train.py single_speaker \
    --audio_dir ./new_voice \
    --output_dir ./new_voice_model
# Ð’ train_enhanced.py ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ --pretrain_ckpt ./universal_model/model_last.pt
```

### ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ñ‘Ð½Ð½Ñ‹Ð¹ ÑÑ‚Ð¸Ð»ÑŒ (Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸, Ð°ÑƒÐ´Ð¸Ð¾ÐºÐ½Ð¸Ð³Ð¸)

```bash
# Ð¡Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ð³Ð¾ ÑÑ‚Ð¸Ð»Ñ
# metadata.csv â€” Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸
python custom_train.py emotional \
    --audio_dir ./news_data \
    --metadata ./news_metadata.csv \
    --output_dir ./news_model
```

### ÐšÑ€Ð¾ÑÑ-Ð»Ð¸Ð½Ð³Ð²Ð°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (ENâ†’RU)

```bash
# Ð”Ð°Ð½Ð½Ñ‹Ðµ: Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸ + Ñ€ÑƒÑÑÐºÐ¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸
# ÐŸÑ€Ð¸ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐµ: Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ â†’ Ñ€ÑƒÑÑÐºÐ°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
# ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ‚ÐµÐ¼Ð±Ñ€ Ð¸Ð· EN Ð¸ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð½Ð° RU

python custom_train.py test \
    --checkpoint ./universal_model/model_last.pt \
    --ref_audio english_speaker.wav \
    --text "Ð­Ñ‚Ð¾ Ñ€ÑƒÑÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚, Ð¾Ð·Ð²ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¼ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð¼."
```

### ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ‡ÐµÑ€ÐµÐ· Wandb

```bash
# Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ --logger wandb Ðº Ð»ÑŽÐ±Ð¾Ð¼Ñƒ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸ÑŽ
python custom_train.py single_speaker \
    --audio_dir ./my_voice \
    --output_dir ./my_model \
    --logger wandb
```

---

## Troubleshooting

### CUDA Out of Memory

```bash
# Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚ÑŒ batch + Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ cross-attention
python train_enhanced.py \
    --batch_size_per_gpu 4800 \
    --max_samples 8 \
    --grad_accumulation_steps 8 \
    --no_cross_attn \
    ...
```

### Loss Ð½Ðµ Ð¿Ð°Ð´Ð°ÐµÑ‚

1. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ñ‡Ñ‚Ð¾ Ð½Ðµ Ð²ÑÑ‘ Ð·Ð°Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ð¾:
```python
model = load_enhanced_model("model_last.pt")
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Trainable: {trainable:,}")  # Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ ~20M
```

2. Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ñ‚ÑŒ LR: `--learning_rate 5e-4`

3. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ: `python -m f5_tts.scripts.prepare_data --stage verify ...`

### ÐÑ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ Ð² Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸

- Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚ÑŒ `emotion_cfg_strength` (2.0 â†’ 1.0)
- Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ñ‚ÑŒ `steps` (32 â†’ 48)
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ (3-10 ÑÐµÐºÑƒÐ½Ð´)
- Ð”Ð¾Ð¾Ð±ÑƒÑ‡Ð¸Ñ‚ÑŒ ÐµÑ‰Ñ‘ 1-2 ÑÐ¿Ð¾Ñ…Ð¸

### Ð“Ð¾Ð»Ð¾Ñ Ð½Ðµ Ð¿Ð¾Ñ…Ð¾Ð¶ Ð½Ð° Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ

- ÐžÐ±ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð¾Ð»ÑŒÑˆÐµ (Ð±Ð¾Ð»ÑŒÑˆÐµ ÑÐ¿Ð¾Ñ…)
- Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ†ÐµÐ»ÐµÐ²Ð¾Ð³Ð¾ ÑÐ¿Ð¸ÐºÐµÑ€Ð°
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð¸ÑÑ‚Ñ‹Ð¹ Ñ€ÐµÑ„ÐµÑ€ÐµÐ½Ñ
- ÐŸÐ¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ Stage 2 Ñ `--unfreeze_top_k 4`
